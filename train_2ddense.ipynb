{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T20:42:27.744197Z",
     "start_time": "2019-03-30T20:42:21.334132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test ImageNet pretrained DenseNet\"\"\"\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "#sys.path.insert(0,'Keras-2.0.8')\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import random\n",
    "from medpy.io import load\n",
    "import numpy as np\n",
    "import argparse\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from loss import weighted_crossentropy_2ddense\n",
    "import os\n",
    "#from keras.utils2.multi_gpu import make_parallel\n",
    "from denseunet import DenseUNet\n",
    "from skimage.transform import resize\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T20:50:38.024236Z",
     "start_time": "2019-03-30T20:50:38.007649Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-data DATA] [-save_path SAVE_PATH] [-b B]\n",
      "                             [-input_size INPUT_SIZE]\n",
      "                             [-model_weight MODEL_WEIGHT]\n",
      "                             [-input_cols INPUT_COLS] [-mean MEAN]\n",
      "                             [-thread_num THREAD_NUM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-519be400-9136-4f2d-8378-0f3f09e6ce0b.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#  global parameters\n",
    "parser = argparse.ArgumentParser(description='Keras 2d denseunet Training')\n",
    "#  data folder\n",
    "parser.add_argument('-data', type=str, default='data/', help='test images')\n",
    "parser.add_argument('-save_path', type=str, default='Experiments/')\n",
    "#  other paras\n",
    "parser.add_argument('-b', type=int, default=40)\n",
    "parser.add_argument('-input_size', type=int, default=224)\n",
    "parser.add_argument('-model_weight', type=str, default='./model/densenet161_weights_tf.h5')\n",
    "parser.add_argument('-input_cols', type=int, default=3)\n",
    "\n",
    "#  data augment\n",
    "parser.add_argument('-mean', type=int, default=48)\n",
    "parser.add_argument('-thread_num', type=int, default=14)\n",
    "args = parser.parse_args()\n",
    "\n",
    "MEAN = args.mean\n",
    "thread_num = args.thread_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T20:47:08.008992Z",
     "start_time": "2019-03-30T20:47:07.981985Z"
    }
   },
   "outputs": [],
   "source": [
    "#liverlist = [32,34,38,41,47,87,89,91,105,106,114,115,119]\n",
    "liverlist = [32,34,38,41,47,51,57,69,75,83,87,93,101]\n",
    "def load_seq_crop_data_masktumor_try(Parameter_List):\n",
    "    img = Parameter_List[0]\n",
    "    tumor = Parameter_List[1]\n",
    "    lines = Parameter_List[2]\n",
    "    numid = Parameter_List[3]\n",
    "    minindex = Parameter_List[4]\n",
    "    maxindex = Parameter_List[5]\n",
    "    #  randomly scale\n",
    "    scale = np.random.uniform(0.8,1.2)\n",
    "    deps = int(args.input_size * scale)\n",
    "    rows = int(args.input_size * scale)\n",
    "    cols = 3\n",
    "\n",
    "    #sed = np.random.randint(1,numid)\n",
    "    sed = np.random.randint(numid)\n",
    "    cen = lines[sed-1]\n",
    "    cen = np.fromstring(cen, dtype=int, sep=' ')\n",
    "\n",
    "    a = min(max(minindex[0] + deps//2, cen[0]), maxindex[0]- deps//2-1)\n",
    "    b = min(max(minindex[1] + rows//2, cen[1]), maxindex[1]- rows//2-1)\n",
    "    c = min(max(minindex[2] + cols//2, cen[2]), maxindex[2]- cols//2-1)\n",
    "    cropp_img = img[a - deps // 2:a + deps // 2, b - rows // 2:b + rows // 2,\n",
    "                c - cols // 2: c + cols // 2 + 1].copy()\n",
    "    cropp_tumor = tumor[a - deps // 2:a + deps // 2, b - rows // 2:b + rows // 2,\n",
    "                  c - cols // 2:c + cols // 2 + 1].copy()\n",
    "\n",
    "    cropp_img -= MEAN\n",
    "     # randomly flipping\n",
    "    flip_num = np.random.randint(0, 8)\n",
    "    if flip_num == 1:\n",
    "        cropp_img = np.flipud(cropp_img)\n",
    "        cropp_tumor = np.flipud(cropp_tumor)\n",
    "    elif flip_num == 2:\n",
    "        cropp_img = np.fliplr(cropp_img)\n",
    "        cropp_tumor = np.fliplr(cropp_tumor)\n",
    "    elif flip_num == 3:\n",
    "        cropp_img = np.rot90(cropp_img, k=1, axes=(1, 0))\n",
    "        cropp_tumor = np.rot90(cropp_tumor, k=1, axes=(1, 0))\n",
    "    elif flip_num == 4:\n",
    "        cropp_img = np.rot90(cropp_img, k=3, axes=(1, 0))\n",
    "        cropp_tumor = np.rot90(cropp_tumor, k=3, axes=(1, 0))\n",
    "    elif flip_num == 5:\n",
    "        cropp_img = np.fliplr(cropp_img)\n",
    "        cropp_tumor = np.fliplr(cropp_tumor)\n",
    "        cropp_img = np.rot90(cropp_img, k=1, axes=(1, 0))\n",
    "        cropp_tumor = np.rot90(cropp_tumor, k=1, axes=(1, 0))\n",
    "    elif flip_num == 6:\n",
    "        cropp_img = np.fliplr(cropp_img)\n",
    "        cropp_tumor = np.fliplr(cropp_tumor)\n",
    "        cropp_img = np.rot90(cropp_img, k=3, axes=(1, 0))\n",
    "        cropp_tumor = np.rot90(cropp_tumor, k=3, axes=(1, 0))\n",
    "    elif flip_num == 7:\n",
    "        cropp_img = np.flipud(cropp_img)\n",
    "        cropp_tumor = np.flipud(cropp_tumor)\n",
    "        cropp_img = np.fliplr(cropp_img)\n",
    "        cropp_tumor = np.fliplr(cropp_tumor)\n",
    "\n",
    "    cropp_tumor = resize(cropp_tumor, (args.input_size,args.input_size,args.input_cols), order=0, mode='edge', cval=0, clip=True, preserve_range=True)\n",
    "    cropp_img   = resize(cropp_img, (args.input_size,args.input_size,args.input_cols), order=3, mode='constant', cval=0, clip=True, preserve_range=True)\n",
    "    return cropp_img, cropp_tumor[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T20:47:19.788118Z",
     "start_time": "2019-03-30T20:47:19.771702Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_arrays_from_file(batch_size, trainidx, img_list, tumor_list, tumorlines, liverlines, tumoridx, liveridx, minindex_list, maxindex_list):\n",
    "    while 1:\n",
    "        X = np.zeros((batch_size, args.input_size, args.input_size, args.input_cols), dtype='float32')\n",
    "        Y = np.zeros((batch_size, args.input_size, args.input_size, 1), dtype='int16')\n",
    "        Parameter_List = []\n",
    "        for idx in range(batch_size):\n",
    "            print(trainidx)\n",
    "            count = random.choice(trainidx)\n",
    "            img = img_list[count]\n",
    "            tumor = tumor_list[count]\n",
    "            minindex = minindex_list[count]\n",
    "            maxindex = maxindex_list[count]\n",
    "            num = np.random.randint(0,6)\n",
    "            if num < 3 or (count in liverlist):\n",
    "                lines = liverlines[count]\n",
    "                numid = liveridx[count]\n",
    "            else:\n",
    "                lines = tumorlines[count]\n",
    "                numid = tumoridx[count]\n",
    "            Parameter_List.append([img, tumor, lines, numid, minindex, maxindex])\n",
    "        pool = ThreadPool(thread_num)\n",
    "        result_list = pool.map(load_seq_crop_data_masktumor_try, Parameter_List)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        for idx in range(len(result_list)):\n",
    "            X[idx, :, :, :] = result_list[idx][0]\n",
    "            Y[idx, :, :, 0] = result_list[idx][1]\n",
    "        yield (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T20:47:38.915733Z",
     "start_time": "2019-03-30T20:47:38.893286Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_fast_files(args):\n",
    "\n",
    "    trainidx = list(range(0,131-28))\n",
    "    #trainidx = list(range(0,131))\n",
    "    img_list = []\n",
    "    tumor_list = []\n",
    "    minindex_list = []\n",
    "    maxindex_list = []\n",
    "    tumorlines = []\n",
    "    tumoridx = []\n",
    "    liveridx = []\n",
    "    liverlines = []\n",
    "    for idx in range(28, 131):\n",
    "        img, img_header = load(args.data+ 'myTrainingData/volume-' + str(idx) + '.nii')\n",
    "        tumor, tumor_header = load(args.data + 'TrainingData/segmentation-' + str(idx) + '.nii')\n",
    "        max_limit = min(img.shape[2],tumor.shape[2])\n",
    "        img_list.append(img)\n",
    "        tumor_list.append(tumor)\n",
    "\n",
    "        maxmin = np.loadtxt(args.data + 'myTrainingDataTxt/LiverBox/box_' + str(idx) + '.txt', delimiter=' ')\n",
    "        minindex = maxmin[0:3]\n",
    "        maxindex = maxmin[3:6]\n",
    "        minindex = np.array(minindex, dtype='int')\n",
    "        maxindex = np.array(maxindex, dtype='int')\n",
    "        minindex[0] = max(minindex[0] - 3, 0)\n",
    "        minindex[1] = max(minindex[1] - 3, 0)\n",
    "        minindex[2] = max(minindex[2] - 3, 0)\n",
    "        maxindex[0] = min(img.shape[0], maxindex[0] + 3)\n",
    "        maxindex[1] = min(img.shape[1], maxindex[1] + 3)\n",
    "        maxindex[2] = min(img.shape[2], maxindex[2] + 3)\n",
    "        minindex_list.append(minindex)\n",
    "        maxindex_list.append(maxindex)\n",
    "        f1 = open(args.data + 'myTrainingDataTxt/TumorPixels/tumor_' + str(idx) + '.txt', 'r')\n",
    "        tumorline = f1.readlines()\n",
    "        tumorlines.append(tumorline)\n",
    "        tumoridx.append(len(tumorline))\n",
    "        f1.close()\n",
    "        f2 = open(args.data + 'myTrainingDataTxt/LiverPixels/liver_' + str(idx) + '.txt', 'r')\n",
    "        liverline = f2.readlines()\n",
    "        liverlines.append(liverline)\n",
    "        liveridx.append(len(liverline))\n",
    "        f2.close()\n",
    "\n",
    "    return trainidx, img_list, tumor_list, tumorlines, liverlines, tumoridx, liveridx, minindex_list, maxindex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T20:47:57.260581Z",
     "start_time": "2019-03-30T20:47:57.241944Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_predict():\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "\n",
    "    model = DenseUNet(reduction=0.5, args=args)\n",
    "    model.load_weights(args.model_weight, by_name=True)\n",
    "    #model = make_parallel(model, args.b/10, mini_batch=10) # edited by vijay\n",
    "    sgd = SGD(lr=1e-3, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss=[weighted_crossentropy_2ddense])\n",
    "\n",
    "    trainidx, img_list, tumor_list, tumorlines, liverlines, tumoridx, liveridx, minindex_list, maxindex_list = load_fast_files(args)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model......')\n",
    "    print('-'*30)\n",
    "\n",
    "    if not os.path.exists(args.save_path):\n",
    "        os.mkdir(args.save_path)\n",
    "\n",
    "    if not os.path.exists(args.save_path + \"model\"):\n",
    "        os.mkdir(args.save_path + 'model')\n",
    "        os.mkdir(args.save_path + 'history')\n",
    "    else:\n",
    "        if os.path.exists(args.save_path+ \"history/lossbatch.txt\"):\n",
    "            os.remove(args.save_path + 'history/lossbatch.txt')\n",
    "        if os.path.exists(args.save_path + \"history/lossepoch.txt\"):\n",
    "            os.remove(args.save_path + 'history/lossepoch.txt')\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(args.save_path + 'model/weights.{epoch:02d}-{loss:.2f}.hdf5', monitor='loss', verbose = 1,\n",
    "                                       save_best_only=False,save_weights_only=False,mode = 'min', period = 1)\n",
    "                                       \n",
    "   # model_checkpoint = ModelCheckpoint(args.save_path + 'model/weights.{epoch:02d}-{loss:.2f}.hdf5', monitor='loss', verbose = 1,save_best_only=False,save_weights_only=False,mode = 'min', period = 1)\n",
    "\n",
    "    steps = 27386//args.b\n",
    "    model.fit_generator(generate_arrays_from_file(args.b, trainidx, img_list, tumor_list, tumorlines, liverlines, tumoridx,\n",
    "                                                  liveridx, minindex_list, maxindex_list),steps_per_epoch=steps,\n",
    "                                                    epochs= 5, verbose = 1, callbacks = [model_checkpoint], max_queue_size=10,\n",
    "                                                    workers=1, use_multiprocessing=False)\n",
    "    # orignal epoch=6000\n",
    "    print ('Finised Training .......')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T20:48:08.923152Z",
     "start_time": "2019-03-30T20:48:08.678863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4e35e7fcd9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-296ef58b349e>\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#model = make_parallel(model, args.b/10, mini_batch=10) # edited by vijay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_and_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New heading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
